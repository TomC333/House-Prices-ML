# House-Prices-ML

## Kaggle-ის კონკურსის მიმოხილვა

ამ კონკურსის მიზანია, რომ ვივარაუდოთ საცხოვრებელი სახლების ფასები, რისთვისაც შეგვიძლია გამოვიყენოთ 70-ზე მეტი სხვადასხვა ტიპის feature.

## მიდგომა პრობლემის გადასაჭრელად

პრობლემის გადაჭრა დავიწყე მონაცემთა ანალიზით, რისთვისაც გამოვიყენებ სხვადასხვა ფუნქციონალი (.describe(), matplotlib.pyplot ფექეჯი, feature-ებს შორის კავშირის დასანახად) და ამ ყველაფრის საფუძველზე გადავდგი სხვადასხვა ნაბიჯები, რომელიც მოიცავდა მონაცემთა გასუფთავებას, ახალი მახასიათებლების შექმნას, უკვე არსებულების მოდიფიკაციას და საბოლოოდ "საუკეთესო" feature-ების ამორჩევას. ამ პროცესში გამოვიყენე ისეთი ტექნიკები როგორიცაა one hot encoding, hyperparameter optimization, ასევე სხვადასხვა კატეგორიული მახასიათებლების რიცხვად გადაქცევა და ა.შ 


## რეპოზიტორიის სტრუქტურა

- **env.yml** - კონდას გარემოსთვის აუცილებელი dependencies.
- **model_experiment.ipynb** - მოდელების დამუშავების მთელი პროცესი: cleaning, feature engineering, feature selection, training.
- **model_inference.ipynb** - არჩეული მოდელის ტესტირება და პროგნოზების დალოგვა.
- **input/** - ფოლდერი სადაც ვინახავთ train და test csv ფაილებს.


## Feature Engineering

### Cleaning & NaN Values 

ამ ნაწილში ჩემი აზრით დიდი მნიშვნელობა ჰქონდა ფასთან დამოკიდებულებების გრაფიკებს, ზოგიერთი მახასიათებელი ფასთან მიმართებაში საერთოდ არანაირ დამოკიდებულება არ ჰქონდა, ან საერთოდ არ იკვეთებოდა ფასთან მიმართებაში რაიმე დამოკიდებულება, ან ეს მახასიათებლები გრაფიკის ერთ ნაწილში იყვნენ მოქცეული საკმაოდ მჭიდროდ, უბრალოდ ჩავთვალე რომ მსგავსი მახასიათებლები არ გამოგვადგებოდა ამიტომ მათი დადროპვით დავიწყე დატაფრეიმის გასუფთავება, ასევე იყო რამდენიმე feature რომლებსაც საკმაოდ დიდი რაოდენობით ჰქონდათ NaN მნიშვნელობები (90%, 80%) როცა მივხვდი რომ ვერცერთი სხვა ცვლადის გამოყენებით ვერ შევავსებდით მათ უბრალოდ მათი დადროპვაც გადავწყვიტე.

თუმცა გვქონდა ისეთი ცვლადებიც რომლებიც სხვა რომელიმეზე იყვნენე დამოკიდებული და ამით შეგვეძლო ამ NaN ზე ინფორმაციის მიღება, მაგალითად ერთ-ერთი მახასიათებელი არის 'GarageArea' რომელსაც არცერთი NaN მნიშვნელობა არ ჰქონია, თუმცა გვქონდა ძალიან ბევრი NaN მნიშვნელობა 'GarageCond', 'GarageQual', 'GarageFinish', 'GarageYrBlt', 'GarageType' ამ ცვლადებში, მათ შორის ძალიან მარტივი კავშირით სრუილიად ყველა NaN მნიშვნელობის ჩანაცვლება მოვახერხე (სადაც GarageAre 0-ის ტოლი იყო სწორედ ასეთ შემთხვევებში ჰქონდათ ამ ცვლადებს NaN მნიშვნელობები...). ასეთი ერთმანეთთან დალინკული სხვა რამდენიმე მახასიათებელიც გვქონდა და მათ შემთხვევაშიც ანალოგიურად მოვიქეცი 

### Outliers

გრაფიკებზე დაკვირვებისას ასევე აღმოვაჩინე რამდენიმე outlier ძირითადად რამდენიმ წერტილი იყო ასეთი თუმცა ჩავთვალე რომ ამ წერტილებს შესაძლოა დიდი გავლენა ჰქონოდათ საბოლოო შედეგზე ამიტომ უბრალოდ მათი შესაბამის როუები წავშალე, მაგალითად 'LotFrontage' და 'SalePrice' ების დამოკიდებულების გრაფიკზე, LotFrontage-ს ზრდასთან ერთად SalePrice-ის მინიმალური მნიშვნელობაც იზრდებოდა, თუმცა ბოლოსკენ გვქონდა 2 წერტილი, სადაც ფასები ძალიან დაბალი იყო.. ანალოგირუად გვქონდა სხვა რამდენიმე მახასიათებლის შემთხვევაშიც, საბოლოო ჯამში დაახლოებით 10 row თი ნაკლები მივიღეთ ალბათ...   


### კატეგორიული ცვლადების რიცხვითში გადაყვანა

ამ ყველაფრის შემდეგ კი ვცადე რამდენიმე კატეგორიული ცვლადის გადაყვანა რიცხვით ცვლადში. არაფერი განსაკუთრებული პატარა დიქშენარი გავაკეთე სადაც აღწერილი იყო კონკრეტული მახასიათებლების მნიშვნელობები და ამ მნიშვნელობების შესაბამისი რიცხვები 

“““
mappings = {
    "MSSubClass": {
        '20': 1, '30': 2, '40': 3, '45': 4, '50': 5, '60': 6, '70': 7, '75': 8, '80': 9,
        '85': 10, '90': 11, '120': 12, '150': 13, '160': 14, '180': 15, '190': 16
    },
    "Alley": {"Unknown": -1, "NA": 0, "Grvl": 1, "Pave": 2},
    "LotShape": {"IR3": 0, "IR2": 1, "IR1": 2, "Reg": 3},
    "LandContour": {"Low": 0, "HLS": 1, "Bnk": 2, "Lvl": 3},
    "LandSlope": {"Sev": 0, "Mod": 1, "Gtl": 2},
    "ExterQual": {"Po": 1, "Fa": 2, "TA": 3, "Gd": 4, "Ex": 5},
    "ExterCond": {"Po": 1, "Fa": 2, "TA": 3, "Gd": 4, "Ex": 5},
    "BsmtQual": {"NA": 0, "Po": 1, "Fa": 2, "TA": 3, "Gd": 4, "Ex": 5},
    "BsmtCond": {"NA": 0, "Po": 1, "Fa": 2, "TA": 3, "Gd": 4, "Ex": 5},
    "BsmtExposure": {"NA": 0, "No": 1, "Mn": 2, "Av": 3, "Gd": 4},
    "BsmtFinType1": {"NA": 0, "Unf": 1, "LwQ": 2, "Rec": 3, "BLQ": 4, "ALQ": 5, "GLQ": 6},
    "HeatingQC":    { "Po": 1, "Fa": 2, "TA": 3, "Gd": 4, "Ex": 5 },
    "KitchenQual":  { "Po": 1, "Fa": 2, "TA": 3, "Gd": 4, "Ex": 5  },
    "Functional":   { "Sal": 0, "Sev": 1, "Maj2": 2, "Maj": 3, "Mod": 4, "Min2": 5, "Min1": 6, "Typ": 7 },
    "FireplaceQu":  { "Na": 0, "Po": 1, "Fa": 2, "TA": 3, "Gd": 4, "Ex": 5  },
    "GarageFinish": { "Na": 0, "Unf": 1, "RFn": 2, "Fin": 3 },
    "GarageQual":   { "NA": 0, "Po": 1, "Fa": 2, "TA": 3, "Gd": 4, "Ex": 5 },
    "GarageCond":   { "NA": 0, "Po": 1, "Fa": 2, "TA": 3, "Gd": 4, "Ex": 5 },
}
“““

### ახალი მახასიათებლების შექმნა 

კვლავ დაკვირვების საფუძველზე დავაკვირდი რომ ზოგერთი ცვლადის მნიშვნელობაზე მეტად ფასზე გავლენას უშუალოდ ამ ცვლადის არსებობა ან არარსებობდა ახდენდა, სწორედ ამიტომ რამდენიმე მახასიათებელი ჩავანაცვლე მისი არსებობის აღმნიშვნელით, მაგალითად PoolArea ჩავანაცვლე Pool?, რომელიც გვეუბნება აუზი აქვს თუ არა სახლს, Fireplaces - Fireplace? და ა.შ მსგავს მარტივ მახასიათებლებთან ერთად დავამატე სხვა ოდნავ "რთული" ტიპის ცვლადიც მაგალითად 

“““
train_df["RoomDensity"] = train_df["TotRmsAbvGrd"] / (train_df["GrLivArea"] + 1e-6)
train_df["BedroomsPerRoom"] = train_df["BedroomAbvGr"] / (train_df["TotRmsAbvGrd"] + 1e-6)
“““

მიუხედავად იმისა რომ ახლად შექმნილი ცვლადებიდან ყველა არ გამომიყენებია საბოლოოდ რამდენიმე მაინც გამოვიყენე... 

## Feature Selection

მახასიათებლების არჩევისას მარტივად კორელაციების მატრიცას დავაკვირდი და ამოვარჩიე ისეთი რიცხვითი ცვლადები რომლებსაც შედარებით მაღალი კორელაცია ჰქონდათ გაყიდვის ფასთან, ასევე ავარჩიე რამდენიმე ისეთიც რომლებსაც შედარებით მაღალი უარყოფითი კორელაცია ჰქონდათ, (მათ შორის იყო ერთ-ერთი ჩემივე შექმნილი RoomDensity -0.532006). ხოლო კატეგორიული ცვლადების არჩევისას ისევ თავდაპირველ გრაფიკებს დავბრუნდი, ამორჩეულ კატეგორიულ ცვლადებზე გამოვყენე one hot encoding. ენკოდირების შემდეგ დატა დავატრეინე და საბოლოოდ მოდელი ტესტ დატაზეც გავუშვი მაგრამ ამ დროს მოხდა შეცდომა რის შედეგადაც მომიწია ერთ-ერთი კატეგორიული ცვლადის მოდიფიკაცია, როგორც ქვემოთ კოდშია მოცემული.

“““
train_df['HouseStyle'] = train_df['HouseStyle'].map({
    '1.5Unf': 'Unfinished',
    '2.5Unf': 'Unfinished',
    '1Story': 'Finished',
    '1.5Fin': 'Finished',
    '2Story': 'Finished',
    '2.5Fin': 'Finished'
}).fillna('Split')
“““

აღმოჩნდა რომ train დატაფრეიმში რამდენიმე HouseStyle მნიშვნელობა საერთოდ არ გვხვდებოდა, თუ სწორად მახსოვს "2.5Unf" თუმცა ეს მნიშვნელობა გვქონდა test დატაფრეიმში, რამაც გამოიწვია შეცდომა (ენკოდირების დროს ერთგანე დაემატა "2.5Unf" მეორეგან არა და მოდელმა ვეღარ დაამუშავა მიღებული ინფორმაცია)


## Training

მოდელის ტრენინგი ჩატარდა სხვადასხვა ალგორითმებით: LinearRegression, DecisionTreeRegressor, RandomForest, Lasso, და Ridge. თითოეული მოდელი დატრეინდა 80%-იანი ტრეინ სეტით და 20%-იანი ვალიდაციის სეტით.

- **MLflow ექსპერიმენტების ბმული**: [Link to MLflow Experiments](https://dagshub.com/TomC333/House-Prices-ML/experiments)

## ტესტირებული მოდელები

- **Linear Regression** - [Link to Experiment](https://dagshub.com/TomC333/House-Prices-ML/experiments#/experiment/m_338a10359b9f44b1bb2a9c9b2bc1db70)
- **DecisionTreeRegressor** - [Link to Experiment](https://dagshub.com/TomC333/House-Prices-ML/experiments#/experiment/m_da9c04acf6f149c0bf9fe158d517558b)
- **RandomForestRegressor** - [Link to Experiment](https://dagshub.com/TomC333/House-Prices-ML/experiments#/experiment/m_f3cc2a55b4ad444981b94e1ca340e682)
- **RandomForest_Deep** - [Link to Experiment](https://dagshub.com/TomC333/House-Prices-ML/experiments#/experiment/m_4387c21bc63840b18229ee66883af574)
- **DummyRegressor** - [Link to Experiment](https://dagshub.com/TomC333/House-Prices-ML/experiments#/experiment/m_5094a9aa19b04d189d1e4a780ef941a6)
- **RidgeRegression** - [Link to Experiment](https://dagshub.com/TomC333/House-Prices-ML/experiments#/experiment/m_7b7d0c3883cd43018064ac7a10620b21)
- **LassoRegression** - [Link to Experiment](https://dagshub.com/TomC333/House-Prices-ML/experiments#/experiment/m_0996533bc76047769617c7c9b248a251)


## საბოლოო მოდელის შერჩევa 

საბოლოო მოდელად ავარჩიე **RandomForest_Deep**. მიუხედავად იმისა, რომ ამ მოდელს ჰქონდა overfitting, ის მაინც აჩვენებდა საუკეთესო შედეგებს ვალიდაციის სეტზე, უფრო მაღალი r2 და დაბალ RMSE-ს მქონდა. თუმცა როცა დავასაბიმტე ამ მოდელის ქულა იყო 1.3, ჩემდა გასაკვირად ყველაზე კარგი შედეგი არჩვენა **DummyRegressor** (0.4....) და სიმართლე ვთქვა ვერ ვხვდები რატო, დაახლოებით 3.5 ჯერ მეტი RMSE ქონდა ... 

## ჩაწერილი მეტრიკების აღწერა

- r2_train: როგორ ერგება მოდელი ტრეინინგ დატას, (0-1)
- rmse_train (root mean squared error): მოდელის შეცდომის მაჩვენებელი
- r2_val: ვალიდაციის სეტზე სწორად გაკეთებული პროგნოზების მაჩვენებელი
- rmse_val: ვალიდაციის სეტზე მოდელის შეცდომა

## საუკეთესო მოდელის შედეგები

დასკვნის სახით, საუკეთესო შედეგები DummyRegressor-ის მოდელმა აჩვენა ტესტ სეტზე, დასაბმიტების მერე, რაც ჩემი აზრით არაპროგნოზირებადი შედეგი იყო ;დ.

